{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "150e6df6-2e6b-4f2b-9c89-b3f6f895810d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All datasets loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    # Load datasets with proper error handling\n",
    "    country_codes = pd.read_csv(\"Country_codes.csv\")\n",
    "    gdp_data = pd.read_csv(\"GDP_Data.csv\", delimiter=\"\\t\")\n",
    "    literacy_data = pd.read_csv(\"Literacy_Data.csv\", delimiter=\",\")\n",
    "    unemployment_data = pd.read_csv(\"Unemployment_Data.csv\", delimiter=\"\\t\")\n",
    "    migration_data = pd.read_csv(\"Migration_Data.csv\", sep=\",\", skipinitialspace=True)\n",
    "    \n",
    "    print(\"All datasets loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading datasets: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14ee2d07-48de-4ed3-8444-7bd120ccc46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDP columns: ['Country Code', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
      "Literacy columns: ['Country Code', 'year', 'Literacy']\n",
      "Unemployment columns: ['Country Code', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
      "Migration columns: ['Country Code', 'Indicator Name', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n"
     ]
    }
   ],
   "source": [
    "# Clean column names consistently across all dataframes\n",
    "def clean_columns(df):\n",
    "    \"\"\"Clean column names by stripping whitespace and converting to consistent case\"\"\"\n",
    "    df.columns = df.columns.str.strip()\n",
    "    return df\n",
    "\n",
    "gdp_data = clean_columns(gdp_data)\n",
    "literacy_data = clean_columns(literacy_data)\n",
    "unemployment_data = clean_columns(unemployment_data)\n",
    "migration_data = clean_columns(migration_data)\n",
    "country_codes = clean_columns(country_codes)\n",
    "\n",
    "# Display column names for verification\n",
    "print(\"GDP columns:\", gdp_data.columns.tolist())\n",
    "print(\"Literacy columns:\", literacy_data.columns.tolist())\n",
    "print(\"Unemployment columns:\", unemployment_data.columns.tolist())\n",
    "print(\"Migration columns:\", migration_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b312940-b06d-4085-aecb-96c89b83f55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to melt yearly data consistently\n",
    "def melt_yearly_data(df, id_vars=None, value_name=\"Value\"):\n",
    "    \"\"\"Convert wide-format yearly data to long format\"\"\"\n",
    "    if id_vars is None:\n",
    "        id_vars = [\"Country Code\"]\n",
    "    \n",
    "    # Identify year columns (those that are digits)\n",
    "    year_columns = [col for col in df.columns if str(col).isdigit()]\n",
    "    \n",
    "    # Perform melting operation\n",
    "    melted_df = pd.melt(\n",
    "        df,\n",
    "        id_vars=id_vars,\n",
    "        value_vars=year_columns,\n",
    "        var_name=\"Year\",\n",
    "        value_name=value_name\n",
    "    )\n",
    "    \n",
    "    # Ensure Year is converted to string consistently\n",
    "    melted_df[\"Year\"] = melted_df[\"Year\"].astype(str)\n",
    "    \n",
    "    return melted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8468fbc3-24b8-4a16-9d3e-6373d92553b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDP data melted successfully\n",
      "\n",
      "   Country Code  Year        GDP\n",
      "0           ABW  2000   6.519224\n",
      "1           AFE  2000   0.570581\n",
      "2           AFG  2000        NaN\n",
      "3           AFW  2000   1.049676\n",
      "4           AGO  2000  -0.302928\n",
      "5           ALB  2000   7.630022\n",
      "6           AND  2000   3.567766\n",
      "7           ARB  2000   3.815985\n",
      "8           ARE  2000   3.631933\n",
      "9           ARG  2000  -1.906841\n",
      "10          ARM  2000   4.130759\n",
      "11          ASM  2000        NaN\n",
      "12          ATG  2000   4.437025\n",
      "13          AUS  2000   2.738930\n",
      "14          AUT  2000   2.941684\n",
      "15          AZE  2000  10.191029\n",
      "16          BDI  2000  -2.895428\n",
      "17          BEL  2000   3.465478\n",
      "18          BEN  2000   2.650431\n",
      "19          BFA  2000  -1.107107\n",
      "20          BGD  2000   3.386714\n",
      "21          BGR  2000   5.105056\n",
      "22          BHR  2000   2.559648\n",
      "23          BHS  2000   2.790906\n",
      "24          BIH  2000   4.667607\n",
      "25          BLR  2000   6.299636\n",
      "26          BLZ  2000   8.632716\n",
      "27          BMU  2000   8.560550\n",
      "28          BOL  2000   0.762647\n",
      "29          BRA  2000   2.962220\n"
     ]
    }
   ],
   "source": [
    "# Process GDP data\n",
    "try:\n",
    "    gdp_melted = melt_yearly_data(gdp_data, value_name=\"GDP\")\n",
    "    print(\"GDP data melted successfully\\n\")\n",
    "    print(gdp_melted.head(30))\n",
    "except Exception as e:\n",
    "    print(f\"Error processing GDP data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c960b67-a30a-4a79-8988-c61fb027a744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unemployment data melted successfully\n",
      "\n",
      "   Country Code  Year  Unemployment\n",
      "0           ABW  2000         6.920\n",
      "1           AFE  2000           NaN\n",
      "2           AFG  2000           NaN\n",
      "3           AFW  2000           NaN\n",
      "4           AGO  2000           NaN\n",
      "5           ALB  2000        16.800\n",
      "6           AND  2000           NaN\n",
      "7           ARB  2000           NaN\n",
      "8           ARE  2000         2.250\n",
      "9           ARG  2000        15.000\n",
      "10          ARM  2000           NaN\n",
      "11          ASM  2000         5.050\n",
      "12          ATG  2000           NaN\n",
      "13          AUS  2000         6.288\n",
      "14          AUT  2000         4.687\n",
      "15          AZE  2000        11.780\n",
      "16          BDI  2000           NaN\n",
      "17          BEL  2000         6.586\n",
      "18          BEN  2000           NaN\n",
      "19          BFA  2000           NaN\n",
      "20          BGD  2000         3.270\n",
      "21          BGR  2000        16.218\n",
      "22          BHR  2000           NaN\n",
      "23          BHS  2000           NaN\n",
      "24          BIH  2000           NaN\n",
      "25          BLR  2000         2.100\n",
      "26          BLZ  2000           NaN\n",
      "27          BMU  2000         2.710\n",
      "28          BOL  2000         4.470\n",
      "29          BRA  2000           NaN\n"
     ]
    }
   ],
   "source": [
    "# Process unemployment data\n",
    "try:\n",
    "    # Check if 'Country Name' is in columns\n",
    "    id_vars = [\"Country Code\"]\n",
    "    if \"Country Name\" in unemployment_data.columns:\n",
    "        id_vars = [\"Country Name\", \"Country Code\"]\n",
    "    \n",
    "    unemployment_melted = melt_yearly_data(unemployment_data, id_vars=id_vars, value_name=\"Unemployment\")\n",
    "    \n",
    "    # Drop 'Country Name' if it exists\n",
    "    if \"Country Name\" in unemployment_melted.columns:\n",
    "        unemployment_melted.drop(columns=[\"Country Name\"], inplace=True)\n",
    "    \n",
    "    print(\"Unemployment data melted successfully\\n\")\n",
    "    print(unemployment_melted.head(30))\n",
    "except Exception as e:\n",
    "    print(f\"Error processing unemployment data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff9cb825-888a-452f-be1a-819aebb70458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Migration data melted successfully\n",
      "\n",
      "   Country Code  Year  Migration\n",
      "0           ABW  2000     1226.0\n",
      "1           AFE  2000  -688533.0\n",
      "2           AFG  2000 -1025973.0\n",
      "3           AFW  2000    29309.0\n",
      "4           AGO  2000    72793.0\n",
      "5           ALB  2000   -60531.0\n",
      "6           AND  2000     -503.0\n",
      "7           ARB  2000   468890.0\n",
      "8           ARE  2000   178469.0\n",
      "9           ARG  2000   -22775.0\n",
      "10          ARM  2000   -52780.0\n",
      "11          ASM  2000    -1068.0\n",
      "12          ATG  2000      263.0\n",
      "13          AUS  2000   111186.0\n",
      "14          AUT  2000    17631.0\n",
      "15          AZE  2000    15938.0\n",
      "16          BDI  2000   -40032.0\n",
      "17          BEL  2000    13952.0\n",
      "18          BEN  2000     3335.0\n",
      "19          BFA  2000     3877.0\n",
      "20          BGD  2000  -512422.0\n",
      "21          BGR  2000   -26211.0\n",
      "22          BHR  2000     2886.0\n",
      "23          BHS  2000      845.0\n",
      "24          BIH  2000     8138.0\n",
      "25          BLR  2000     1812.0\n",
      "26          BLZ  2000     1675.0\n",
      "27          BMU  2000      -50.0\n",
      "28          BOL  2000   -26940.0\n",
      "29          BRA  2000   -45800.0\n"
     ]
    }
   ],
   "source": [
    "# Process migration data\n",
    "try:\n",
    "    migration_melted = melt_yearly_data(migration_data, value_name=\"Migration\")\n",
    "    print(\"Migration data melted successfully\\n\")\n",
    "    print(migration_melted.head(30))\n",
    "except Exception as e:\n",
    "    print(f\"Error processing migration data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f179f645-3bc9-4640-b79d-751d6a18736d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Literacy data processed successfully\n",
      "\n",
      "   Country Code  Year   Literacy\n",
      "0           ABW  2000  16.400000\n",
      "1           ABW  2010  32.080002\n",
      "2           AFG  2014   9.698487\n",
      "3           AFG  2015   9.792360\n",
      "4           AFG  2017  11.777182\n",
      "5           AFG  2020  13.007438\n",
      "6           AFG  2021   9.460000\n",
      "7           AFG  2022  12.597330\n",
      "8           AGO  2011  12.303003\n",
      "9           AGO  2014  15.860000\n",
      "10          AGO  2015  17.436510\n",
      "11          AGO  2019  20.841118\n",
      "12          AGO  2021  22.049187\n",
      "13          AIA  2001  45.220001\n",
      "14          ALB  2001  37.040001\n",
      "15          ALB  2008  39.889999\n",
      "16          ALB  2010  42.061506\n",
      "17          ALB  2011  43.490002\n",
      "18          ALB  2012  45.279999\n",
      "19          ALB  2013  43.755759\n",
      "20          ALB  2014  45.982703\n",
      "21          ALB  2015  48.186364\n",
      "22          ALB  2016  46.984521\n",
      "23          ALB  2017  46.353340\n",
      "24          ALB  2018  49.885806\n",
      "25          ALB  2019  50.712894\n",
      "26          ALB  2020  51.049841\n",
      "27          ALB  2021  51.842510\n",
      "28          ALB  2022  53.268485\n",
      "29          ALB  2023  53.612053\n"
     ]
    }
   ],
   "source": [
    "# Handle literacy data with correct column names\n",
    "try:\n",
    "    # Check if literacy data is already in long format\n",
    "    if \"year\" in literacy_data.columns and \"Literacy\" in literacy_data.columns:\n",
    "        # Already in long format, just rename columns to be consistent\n",
    "        literacy_renamed = literacy_data.rename(columns={\"year\": \"Year\"})\n",
    "    else:\n",
    "        # Need to melt\n",
    "        literacy_renamed = melt_yearly_data(literacy_data, value_name=\"Literacy\")\n",
    "    \n",
    "    # Ensure Year is string type for consistent merging\n",
    "    literacy_renamed[\"Year\"] = literacy_renamed[\"Year\"].astype(str)\n",
    "    \n",
    "    print(\"Literacy data processed successfully\\n\")\n",
    "    print(literacy_renamed.head(30))\n",
    "except Exception as e:\n",
    "    print(f\"Error processing literacy data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "352fc1ff-6e20-4e43-ac07-b76c98eb9197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all 'Year' columns are strings for consistent merging\n",
    "gdp_melted[\"Year\"] = gdp_melted[\"Year\"].astype(str)\n",
    "unemployment_melted[\"Year\"] = unemployment_melted[\"Year\"].astype(str)\n",
    "migration_melted[\"Year\"] = migration_melted[\"Year\"].astype(str)\n",
    "\n",
    "# Sort dataframes by Country Code and Year for proper filling\n",
    "gdp_melted = gdp_melted.sort_values(by=[\"Country Code\", \"Year\"])\n",
    "unemployment_melted = unemployment_melted.sort_values(by=[\"Country Code\", \"Year\"])\n",
    "migration_melted = migration_melted.sort_values(by=[\"Country Code\", \"Year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c2ab9ec-2238-4793-81a5-7fa567e59e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing GDP values: 96\n",
      "Missing Unemployment values: 600\n",
      "Missing Migration values: 24\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values within each country group\n",
    "def fill_group_values(group):\n",
    "    \"\"\"Fill missing values within a group using forward and backward fill\"\"\"\n",
    "    return group.ffill().bfill()\n",
    "\n",
    "# Apply filling to each dataframe\n",
    "gdp_melted[\"GDP\"] = gdp_melted.groupby(\"Country Code\")[\"GDP\"].transform(fill_group_values)\n",
    "unemployment_melted[\"Unemployment\"] = unemployment_melted.groupby(\"Country Code\")[\"Unemployment\"].transform(fill_group_values)\n",
    "migration_melted[\"Migration\"] = migration_melted.groupby(\"Country Code\")[\"Migration\"].transform(fill_group_values)\n",
    "\n",
    "# Check missing values after filling\n",
    "print(\"Missing GDP values:\", gdp_melted[\"GDP\"].isna().sum())\n",
    "print(\"Missing Unemployment values:\", unemployment_melted[\"Unemployment\"].isna().sum())\n",
    "print(\"Missing Migration values:\", migration_melted[\"Migration\"].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bd0f4e4-13cc-43fa-bff8-baea1bcfc6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data merged successfully!\n"
     ]
    }
   ],
   "source": [
    "# Merge all datasets\n",
    "try:\n",
    "    # Start with GDP\n",
    "    merged_data = gdp_melted.copy()\n",
    "    \n",
    "    # Merge with Unemployment\n",
    "    merged_data = pd.merge(\n",
    "        merged_data,\n",
    "        unemployment_melted,\n",
    "        on=[\"Country Code\", \"Year\"],\n",
    "        how=\"outer\"\n",
    "    )\n",
    "    \n",
    "    # Merge with Migration\n",
    "    merged_data = pd.merge(\n",
    "        merged_data,\n",
    "        migration_melted,\n",
    "        on=[\"Country Code\", \"Year\"],\n",
    "        how=\"outer\"\n",
    "    )\n",
    "    \n",
    "    # Merge with Literacy\n",
    "    merged_data = pd.merge(\n",
    "        merged_data,\n",
    "        literacy_renamed[[\"Country Code\", \"Year\", \"Literacy\"]],\n",
    "        on=[\"Country Code\", \"Year\"],\n",
    "        how=\"outer\"\n",
    "    )\n",
    "    \n",
    "    # Sort final dataset\n",
    "    merged_data = merged_data.sort_values(by=[\"Country Code\", \"Year\"]).reset_index(drop=True)\n",
    "    \n",
    "    print(\"All data merged successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during merging: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64875a66-07a0-469c-8cd7-0497a9e89adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in final dataset:\n",
      "\n",
      "Country Code       0\n",
      "Year               0\n",
      "GDP              110\n",
      "Unemployment     614\n",
      "Migration         38\n",
      "Literacy        4364\n",
      "dtype: int64\n",
      "Preview of final merged dataset:\n",
      "\n",
      "   Country Code  Year        GDP  Unemployment  Migration   Literacy\n",
      "0           ABW  2000   6.519224          6.92     1226.0  16.400000\n",
      "1           ABW  2001   3.212406          6.90      566.0        NaN\n",
      "2           ABW  2002  -1.628099          6.90      349.0        NaN\n",
      "3           ABW  2003  -0.033839          6.90      329.0        NaN\n",
      "4           ABW  2004   5.026912          6.90      326.0        NaN\n",
      "5           ABW  2005  -2.930823          6.90      594.0        NaN\n",
      "6           ABW  2006  -0.673258          6.90      634.0        NaN\n",
      "7           ABW  2007   2.322678          5.71      672.0        NaN\n",
      "8           ABW  2008   1.061772          5.71      703.0        NaN\n",
      "9           ABW  2009 -12.274936          5.71      743.0        NaN\n",
      "10          ABW  2010  -2.956953         10.60      501.0  32.080002\n",
      "11          ABW  2011   2.610525          8.90      333.0        NaN\n",
      "12          ABW  2012  -2.484648          8.90      317.0        NaN\n",
      "13          ABW  2013   4.855279          8.90      315.0        NaN\n",
      "14          ABW  2014  -2.629615          8.90      333.0        NaN\n",
      "15          ABW  2015  -1.635753          8.90      373.0        NaN\n",
      "16          ABW  2016   0.951538          8.90      405.0        NaN\n",
      "17          ABW  2017   7.040657          8.90      434.0        NaN\n",
      "18          ABW  2018   2.234428          8.90      431.0        NaN\n",
      "19          ABW  2019  -2.496549          8.90      420.0        NaN\n",
      "20          ABW  2020 -25.793230          8.90        0.0        NaN\n",
      "21          ABW  2021  25.154964          8.90      503.0        NaN\n",
      "22          ABW  2022   8.912308          8.90      152.0        NaN\n",
      "23          ABW  2023   4.216132          8.90      147.0        NaN\n",
      "24          AFE  2000   0.570581           NaN  -688533.0        NaN\n",
      "25          AFE  2001   0.860717           NaN  -592931.0        NaN\n",
      "26          AFE  2002   1.163242           NaN  -531528.0        NaN\n",
      "27          AFE  2003   0.294752           NaN  -517323.0        NaN\n",
      "28          AFE  2004   2.803787           NaN  -472255.0        NaN\n",
      "29          AFE  2005   3.378235           NaN  -568306.0        NaN\n",
      "\n",
      "Data successfully saved to Merged_Data.csv\n"
     ]
    }
   ],
   "source": [
    "# Convert Year back to integer if needed for analysis\n",
    "merged_data[\"Year\"] = merged_data[\"Year\"].astype(int)\n",
    "\n",
    "# Check for missing values in final dataset\n",
    "print(\"Missing values in final dataset:\\n\")\n",
    "print(merged_data.isnull().sum())\n",
    "\n",
    "# Preview final dataset\n",
    "print(\"Preview of final merged dataset:\\n\")\n",
    "print(merged_data.head(30))\n",
    "\n",
    "# Save merged data to CSV with error handling\n",
    "try:\n",
    "    merged_data.to_csv(\"Merged_Data.csv\", index=False)\n",
    "    print(\"\\nData successfully saved to Merged_Data.csv\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cdb0e7-c4ee-4773-90e0-50537c892b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
